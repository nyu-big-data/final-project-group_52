{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fluid-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deadly-backup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_small = pd.read_csv(\"/scratch/ll4764/train_small.txt\", sep=\" \", header=None, names=[\"user_id\", \"movie_id\", \"rating\", \"timestamp\"])\n",
    "test_small = pd.read_csv(\"/scratch/ll4764/test_small.txt\", sep=\" \", header=None, names=[\"user_id\", \"movie_id\", \"rating\", \"timestamp\"])\n",
    "val_small = pd.read_csv(\"/scratch/ll4764/val_small.txt\", sep=\" \", header=None, names=[\"user_id\", \"movie_id\", \"rating\", \"timestamp\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "intimate-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_small[\"timestamp\"]\n",
    "del test_small[\"timestamp\"]\n",
    "del val_small[\"timestamp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "documented-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to coo matrix\n",
    "user_len = max(max(train_small[\"user_id\"].max(), test_small[\"user_id\"].max()), val_small[\"user_id\"].max()) + 1\n",
    "\n",
    "movie_len = max(max(train_small[\"movie_id\"].max(), test_small[\"movie_id\"].max()), val_small[\"movie_id\"].max()) + 1\n",
    "\n",
    "mat = sp.sparse.lil_matrix((user_len, movie_len), dtype=np.float32)\n",
    "\n",
    "for _, row in train_small.iterrows():\n",
    "    mat[int(row['user_id']), int(row['movie_id'])] = row[\"rating\"]\n",
    "\n",
    "train_data = mat.tocoo()\n",
    "\n",
    "mat = sp.sparse.lil_matrix((user_len, movie_len), dtype=np.float32)\n",
    "\n",
    "for _, row in test_small.iterrows():\n",
    "    mat[int(row['user_id']), int(row['movie_id'])] = row[\"rating\"]\n",
    "\n",
    "test_data = mat.tocoo()\n",
    "\n",
    "mat = sp.sparse.lil_matrix((user_len, movie_len), dtype=np.float32)\n",
    "\n",
    "for _, row in val_small.iterrows():\n",
    "    mat[int(row['user_id']), int(row['movie_id'])] = row[\"rating\"]\n",
    "\n",
    "val_data = mat.tocoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "upset-champagne",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.030945946\n"
     ]
    }
   ],
   "source": [
    "best_lr = 0\n",
    "best_precision = 0\n",
    "for lr in [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.02, 0.09, 0.1]:\n",
    "    model = LightFM(loss='warp', learning_rate=lr)\n",
    "    model.fit(train_data, epochs=30, num_threads=7)\n",
    "    test_precision = precision_at_k(model, test_data, k=100).mean()\n",
    "    if test_precision > best_precision:\n",
    "        best_precision = test_precision\n",
    "        best_lr = lr\n",
    "\n",
    "print(best_lr)\n",
    "print(best_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "independent-algebra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02\n",
      "0.026858108\n"
     ]
    }
   ],
   "source": [
    "best_lr = 0\n",
    "best_precision = 0\n",
    "for lr in [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.02, 0.09, 0.1]:\n",
    "    model = LightFM(loss='logistic', learning_rate=lr)\n",
    "    model.fit(train_data, epochs=30, num_threads=7)\n",
    "    test_precision = precision_at_k(model, test_data, k=100).mean()\n",
    "    if test_precision > best_precision:\n",
    "        best_precision = test_precision\n",
    "        best_lr = lr\n",
    "\n",
    "print(best_lr)\n",
    "print(best_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "auburn-bones",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03\n",
      "0.028378377\n"
     ]
    }
   ],
   "source": [
    "best_lr = 0\n",
    "best_precision = 0\n",
    "for lr in [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.02, 0.09, 0.1]:\n",
    "    model = LightFM(loss='bpr', learning_rate=lr)\n",
    "    model.fit(train_data, epochs=30, num_threads=7)\n",
    "    test_precision = precision_at_k(model, test_data, k=100).mean()\n",
    "    if test_precision > best_precision:\n",
    "        best_precision = test_precision\n",
    "        best_lr = lr\n",
    "\n",
    "print(best_lr)\n",
    "print(best_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "honest-groove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09\n",
      "0.030523648\n"
     ]
    }
   ],
   "source": [
    "best_lr = 0\n",
    "best_precision = 0\n",
    "for lr in [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.02, 0.09, 0.1]:\n",
    "    model = LightFM(loss='warp-kos', learning_rate=lr)\n",
    "    model.fit(train_data, epochs=30, num_threads=7)\n",
    "    test_precision = precision_at_k(model, test_data, k=100).mean()\n",
    "    if test_precision > best_precision:\n",
    "        best_precision = test_precision\n",
    "        best_lr = lr\n",
    "\n",
    "print(best_lr)\n",
    "print(best_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "nuclear-caribbean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.029172298\n"
     ]
    }
   ],
   "source": [
    "best_lr = 0\n",
    "best_precision = 0\n",
    "for epsilon in [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3]:\n",
    "    model = LightFM(loss='warp', learning_schedule=\"adadelta\", epsilon=epsilon)\n",
    "    model.fit(train_data, epochs=30, num_threads=7)\n",
    "    test_precision = precision_at_k(model, test_data, k=100).mean()\n",
    "    if test_precision > best_precision:\n",
    "        best_precision = test_precision\n",
    "        best_lr = lr\n",
    "\n",
    "print(best_lr)\n",
    "print(best_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "worst-tuesday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.026756758\n"
     ]
    }
   ],
   "source": [
    "best_lr = 0\n",
    "best_precision = 0\n",
    "for epsilon in [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3]:\n",
    "    model = LightFM(loss='logistic', learning_schedule=\"adadelta\", epsilon=epsilon)\n",
    "    model.fit(train_data, epochs=30, num_threads=7)\n",
    "    test_precision = precision_at_k(model, test_data, k=100).mean()\n",
    "    if test_precision > best_precision:\n",
    "        best_precision = test_precision\n",
    "        best_lr = lr\n",
    "\n",
    "print(best_lr)\n",
    "print(best_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dietary-david",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.02660473\n"
     ]
    }
   ],
   "source": [
    "best_lr = 0\n",
    "best_precision = 0\n",
    "for epsilon in [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3]:\n",
    "    model = LightFM(loss='bpr', learning_schedule=\"adadelta\", epsilon=epsilon)\n",
    "    model.fit(train_data, epochs=30, num_threads=7)\n",
    "    test_precision = precision_at_k(model, test_data, k=100).mean()\n",
    "    if test_precision > best_precision:\n",
    "        best_precision = test_precision\n",
    "        best_lr = lr\n",
    "\n",
    "print(best_lr)\n",
    "print(best_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "skilled-intersection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.028783785\n"
     ]
    }
   ],
   "source": [
    "best_lr = 0\n",
    "best_precision = 0\n",
    "for epsilon in [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3]:\n",
    "    model = LightFM(loss='warp-kos', learning_schedule=\"adadelta\", epsilon=epsilon)\n",
    "    model.fit(train_data, epochs=30, num_threads=7)\n",
    "    test_precision = precision_at_k(model, test_data, k=100).mean()\n",
    "    if test_precision > best_precision:\n",
    "        best_precision = test_precision\n",
    "        best_lr = lr\n",
    "\n",
    "print(best_lr)\n",
    "print(best_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-peace",
   "metadata": {},
   "source": [
    "Looks like with loss function is warp, and learning rate is 0.1 and learning schedule is adagrad, the precision at 100 is the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "nutritional-constitutional",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightfm took 1.855205774307251s to train model with 1 threads\n",
      "lightfm took 1.2852675914764404s to train model with 2 threads\n",
      "lightfm took 1.1369330883026123s to train model with 3 threads\n",
      "lightfm took 1.0538420677185059s to train model with 4 threads\n",
      "lightfm took 1.0320796966552734s to train model with 5 threads\n",
      "lightfm took 1.1724066734313965s to train model with 6 threads\n",
      "lightfm took 0.8200721740722656s to train model with 7 threads\n",
      "lightfm took 1.072418212890625s to train model with 8 threads\n",
      "lightfm took 1.1280903816223145s to train model with 9 threads\n"
     ]
    }
   ],
   "source": [
    "def train_model(num_threads):\n",
    "    model = LightFM(loss='warp', learning_rate=0.1)\n",
    "    start = time()\n",
    "    model.fit(train_data, epochs=30, num_threads=num_threads)\n",
    "    print(f\"lightfm took {time() - start}s to train model with {num_threads} threads\")\n",
    "    \n",
    "# get number of threads with fastest training speed \n",
    "for i in range(1, 10):\n",
    "    train_model(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-virginia",
   "metadata": {},
   "source": [
    "When there're 7 threds, lightfm trains the fasted with small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "immediate-triumph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision at 100 is 0.030523648485541344\n"
     ]
    }
   ],
   "source": [
    "model = LightFM(loss='warp', learning_rate=0.1)\n",
    "model.fit(train_data, epochs=30, num_threads=7)\n",
    "test_precision = precision_at_k(model, test_data, k=100).mean()\n",
    "print(f\"precision at 100 is {test_precision} on test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "immediate-aircraft",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision at 100 is 0.03136134520173073 on test data\n"
     ]
    }
   ],
   "source": [
    "model = LightFM(loss='warp', learning_rate=0.1)\n",
    "model.fit(train_data, epochs=30, num_threads=7)\n",
    "test_precision = precision_at_k(model, val_data, k=100).mean()\n",
    "print(f\"precision at 100 is {test_precision} on test data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-password",
   "metadata": {},
   "source": [
    "On full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "written-banana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_small = pd.read_csv(\"/scratch/ll4764/train_full.txt\", sep=\" \", header=None, names=[\"user_id\", \"movie_id\", \"rating\", \"timestamp\"])\n",
    "test_small = pd.read_csv(\"/scratch/ll4764/test_full.txt\", sep=\" \", header=None, names=[\"user_id\", \"movie_id\", \"rating\", \"timestamp\"])\n",
    "val_small = pd.read_csv(\"/scratch/ll4764/val_full.txt\", sep=\" \", header=None, names=[\"user_id\", \"movie_id\", \"rating\", \"timestamp\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "august-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_small[\"timestamp\"]\n",
    "del test_small[\"timestamp\"]\n",
    "del val_small[\"timestamp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "legendary-separate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to coo matrix\n",
    "user_len = max(max(train_small[\"user_id\"].max(), test_small[\"user_id\"].max()), val_small[\"user_id\"].max()) + 1\n",
    "\n",
    "movie_len = max(max(train_small[\"movie_id\"].max(), test_small[\"movie_id\"].max()), val_small[\"movie_id\"].max()) + 1\n",
    "\n",
    "mat = sp.sparse.lil_matrix((user_len, movie_len), dtype=np.float32)\n",
    "\n",
    "for _, row in train_small.iterrows():\n",
    "    mat[int(row['user_id']), int(row['movie_id'])] = row[\"rating\"]\n",
    "\n",
    "train_data = mat.tocoo()\n",
    "\n",
    "mat = sp.sparse.lil_matrix((user_len, movie_len), dtype=np.float32)\n",
    "\n",
    "for _, row in test_small.iterrows():\n",
    "    mat[int(row['user_id']), int(row['movie_id'])] = row[\"rating\"]\n",
    "\n",
    "test_data = mat.tocoo()\n",
    "\n",
    "mat = sp.sparse.lil_matrix((user_len, movie_len), dtype=np.float32)\n",
    "\n",
    "for _, row in val_small.iterrows():\n",
    "    mat[int(row['user_id']), int(row['movie_id'])] = row[\"rating\"]\n",
    "\n",
    "val_data = mat.tocoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = 0\n",
    "best_precision = 0\n",
    "for lr in [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.02, 0.09, 0.1]:\n",
    "    model = LightFM(loss='warp', learning_rate=lr)\n",
    "    model.fit(train_data, epochs=30, num_threads=7)\n",
    "    test_precision = precision_at_k(model, test_data, k=100).mean()\n",
    "    if test_precision > best_precision:\n",
    "        best_precision = test_precision\n",
    "        best_lr = lr\n",
    "\n",
    "print(best_lr)\n",
    "print(best_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-plastic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
